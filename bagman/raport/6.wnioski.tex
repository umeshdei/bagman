\section{Wnioski}

% Złożność algorytmów
\subsection{Złożoność obliczeniowa prostego algorytmu heurystycznego}

Zgodnie z załączonymi wynikami można zauważyć bardzo krótki czas działania prostej
heurystki zaproponowanej przez autorów. Jest to spowodowane kwadratową złożonością 
czasową $ O(n^{2}) $, ponieważ musimy $ n $ razy przejrzeć $ n $ punktów, aby znaleźć
najbliższy. Otrzymujemy dzięki temu bardzo szybki algorytm. Jego wadą jest 
możliwość otrzymania wyniku bardzo oddalonego od optimum. Dzieje się tak dlatego, 
że przy końcowych obliczeniach nie mamy już dużego wyboru następnych odwiedzanych 
punktów, więc ostatnie ścieżki do wyboru mogę być bardzo długie. Wynik działania 
tego algorytmu mógłby być podstawą do uruchomienia algorytmów Steepest lub Greedy, 
które sprawdziłyby, czy w sąsiedztwie nie leżą lepsze rozwiązania. Znacznie skróciło
by to ich czas działania, poprzez start w miejscu, które jest blisko optimum.
Jest jednak możliwość, że punkt początkowy leżałby w pobliżu jakiegoś optimum 
lokalnego, i zawsze zwracany były ten sam wynik, uniemożliwiając odkrycie innych 
optimów i dzięki temu polepszenie wyniku.

\subsection{Odległość od optimum}

Przedstawione wyniki prezentują, że odległość od optimum dla wykonanych obliczeń 
są bardzo zróżnicowane. Najbardziej stabilne prezentuje się algorytm autorski 
dając średnio 25\% nadłożenie trasy. 

Algorytmy Steepest i Greedy lepiej działają dla mniejszych instancji, przy dużych 
znalezione rozwiązanie jest dwukrotnie gorsze od znanego optimum. Dla małych instancji
Greedy znajduje rozwiązanie odległe od optimum ok. 30\%, by w największych osiągnąć 
prawie 170\%. Dla algorytmu Steepest wyniki przedstawiają się pomiędzy 25\%, a ok. 250\%.
W najgorszych uzyskanych przypadkach algorytm Greedy uzyskuje wyniki na poziomie 370\%, 
a Steepest 470\%.

Najbardziej zmienny jest algorytm losowy. Uzyskane dane są niedeterministyczne. Średnia
odległość od optimum wynosi ponad 800\%. W najlepszych przypadkach wyniki uzyskiwane były
na poziomie 500\%, a w najgorszych prawie 2000\% odległości od optimum.

W przypadku alogrytmu Simulated Annealing do testów została wybrana instancja z
$ t_{pocz} = 2~000~000 $ i $ c_{rate} = 0,999999 $ z powodu najlepszych uzyskanych wyników.

\subsection{Uzyskane wyniki}
                                                                       
Zgodnie z uzyskanymi obliczeniami najlepszy algorytmem okazał się prosty algorytm 
heurystyczny. Uzyskuje on, w niektórych przypadkach, wyniki lepsze o ponad 50\% od
drugiego w zestawieniu algorytmu Greedy. Kolejnym algorytmem jest Steepest z wynikami 
nieznacznie gorszymi od algorytmu Greedy. Ostatni w zestawieniu znalazł się algorytm 
losowy.

\subsubsection{Prosty algorytm heurystyczny}

Sukces algorytmu autorskiego opiera się w dużej części na podejściu do problemu. 
Programowanie dynamiczne wybiera w danej chwili najbardziej optymalne rozwiązanie, 
dzięki czemu osiąga w ogólności bardzo dobre wyniki. Istnieją jednak sytuacje, gdy 
rozwiązania zaproponowane przez prosty algorytm heurystyczny może być ponad 2 razy 
gorsze od pozostałych algorytmów. Dzieje się tak w przypadku, gdy ostatnia wybrana 
trasa jest bardzo długa. Dlatego po otrzymaniu rozwiązania należałoby przejrzeć 
sąsiedztwo w poszukiwaniu rozwiązania lepszego umożliwiając, w niektórych przypadkach
usunięciu najdłuższej trasy.

\subsubsection{Algorytm losowy}

Słaby wynik algorytmu wiąże się z jego niedeterminizmem, jak i brakiem wykorzystania 
już osiągniętych informacji. Jest to jedyny algorytm, dla którego nie można określić 
złożoności, gdyż będzie on działał tak długo, aż jego praca zostanie przerwana. Losując 
rozwiązania na bardzo dużych danych wejściowych ciężko osiągnąć jest wynik nawet zbliżony 
do optimum. 

W przypadku małych instancji algorytm ten zwracał wyniki porównywalne z 
pozostałymi algorytmami w o wiele krótszym czasie (nie licząc czasu działania algorytmu
autorskiego). Dla $ n = 10 $ ilość permutacji wynosi:

$$ n! = 10! = 3~628~800 $$

co przy przykładowych 200~000 powtórzeń daje szansę w trafienie w rozwiązanie optymalne:

$$ \frac{200~000}{10!} \cdot 100\% = 5,51\%  $$

Natomiast jeśli podniesiemy $ n = 50 $ otrzymujemy wyniki:

$$ n! = 50! = 3,04 * 10^{64} $$
$$ \frac{200~000}{50!} \cdot 100\% = 6,58 * 10^{-58}\%  $$

A przy $ n = 400 $ wyniki przedstawiają się następująco:

$$ n! = 400! = 6,40 * 10^{870} $$
$$ \frac{200~000}{400!} \cdot 100\% = 3,13 * 10^{-864}\%  $$

Jak więc widać dla dużych $ n $ szanse trafienia w rozwiązanie optymalne są zbliżone do $ 0 $.

Algorytm ten nie wykorzystuje również informacji o już znalezionych rozwiązaniach 
w przypadku generowania nowego, dzięki czemu wygenerowane rozwiązania nie przybliżają
go do optimum.

\subsubsection{Algorytm Greedy i Steepest}

Wyniki uzyskane przez algorytm Greedy są lepsze niż uzyskane przez algorytm Steepest. 
Jest to spowodowane przechodzeniem do najlepszego rozwiązania przez algorytm Steepest. 
Dzięki temu wybiera on najczęściej ścieżkę do najbliższego optimum lokalnego. Algorytm
Greedy natomiast wybiera pierwsze znalezione rozwiązanie, które jest lepsze od dotychczas 
znalezionego, dzięki temu nie zbliża się gwałtownie do żadnego z optimów lokalnych, lecz 
raczej przeszukuje obszar tak długo, aż znajdzie ślepy zaułek.

\subsubsection{Algorytm Tabu search}

Algorytm ten jest w swoim działaniu przybliżony do działania algorytmów Greedy i Steepest.
Jest on jednak minimalizuje ich główną wady, a mianowicie łatwej możliwości utknięcia w 
minimum lokalnym. Zakłada on możliwość pogorszenia wyniku, lecz dzięki posiadanej liście 
tabu nie będzie on działał na tych samych wierzchołkach, lecz przechodził do jeszcze nie 
odwiedzanych. Dzięki temu będzie mógł uniknąć utknięcia w minimum lokalnym, celem znalezienia
minimum globalnego.



\subsubsection{Algorytm symulowane wyżarzanie}

Podobnie jak algorytm Tabu search algorytm ten minimalizuje ryzyko utknięcia w minimum 
lokalnym z powodu wyboru punktu początkowego. W początkowych etapach, gdy temperatura jest 
wysoka możliwe są duże zmiany w uszeregowaniu punktów. Umożliwia nam to opuszczenia minimum
lokalnego, celem znalezienia minimum globalnego. Następnie wraz ze spadkiem temperatury, zmiany 
są coraz mniejsze, aby małymi krokami doprecyzować odnalezione minimum. 

Jak widzimy na wykresach w niektórych przypadkach odległość od optimum jest bardzo mała, znacznie 
mniejsza niż w przypadku algorytmów Greedy i Steepest, i wynosi mniej niż 10\%. 

Algorytm ten wrażliwy jest na zmianę spadku temperatury początkowej, gdyż ma to znaczący 
wpływ na ilość iteracji. Jest ona kluczowa przy wprawnym rozwiązywaniu problemu i powinna być 
uzależniona od wielkości instancji. W przypadku danych wziętych do obliczeń uzyskujemy:

$$ 2~000~000 \cdot 0,999999^{n} < 0,00001 $$
$$ 0,999999^{n} < 5 \cdot 10^{-12} $$
$$ n > \log_{0,999999}10^{-12} $$
$$ n > 26~021~570.19 $$

Jak możemy zauważyć w tym przypadku ilość iteracji wynosi ponad 26 milionów, co pozwala przejrzeć 
dużą ilość rozwiązań i znaleźć rozwiązanie bliskie optimum globalnemu.

O ile zmiana spadku temperatury początkowej jest bardzo istotna dla uzyskanych, o tyle sama 
temperatura początkowa nie jest ważna. Można to zauważyć na wykresach od \ref{999900_Tav} do 
\ref{999999_Tav}, że przy różnych temperaturach początkowych wyniki uzyskiwane przez algorytm 
są do siebie zbliżone. 


\subsection{Efektywność}

Przy porównaniu algorytmów Greedy i Steepest można zauważyć, że algorytm Greedy uzyskuje 
zawsze lepsze wyniki. W większości przypadków wyniki są ok. 2 razy lepsze. Wyjątkiem jest 
zestaw danych \it berlin52 \rm różnica jest minimalna, ok. 4\%. Jest to spowodowane 
bardzo małymi rozmiarami instancji, więc i dużym prawdopodobieństwem znalezienia podobnych
rozwiązań przez oba algorytmy.

Algorytm symulowane wyżarzanie uzyskuje najlepsze wyniki w prezentowanym zestawieniu. Jednak
wymaga więcej czasu w przypadku małych instancji (poniżej 400 elementów). 

\subsection{Czas działania}

\it
W zestawieniu nie został ujęty prosty algorytm heurystyczny z powodu zbyt krótkich czasów 
działania. Dla instancji o rozmiarach ponad 700 elementów pokazywał on czas działania 0.00, 
podczas gdy algorytm Steepest potrzebował ponad 1,5h.
\rm

\subsubsection{Algorytm Greedy}

Czas działania tego algorytmu dla większych instancji jest lepszy o ok. 50 - 70 \% w porównaniu 
do algorytmu Steepest. Pomimo, że potrzebuje on więcej iteracji, przejście do następnego kroku 
zajmuje mniej czasu, gdyż następuje od razu po znalezieniu lepszego rozwiązania. Jego złożoność 
wynosi następująco:

\subsubsection{Algorytm Steepest}

Algorytm ten jest ok. 2 razy gorszy od algorytmu Greedy. Wynika to głównie z fakty, że przegląda on
wszystkie rozwiązania zanim podejmie decyzję o następnym kroku. Zyskuje dzięki temu na mniejszej
ilości iteracji, jednak przeglądając 2 razy więcej rozwiązań sprawia, że każda z iteracji trwa 
dłużej niż w przypadku algorytmu Greedy.

\subsubsection{Algorytm losowy}

Algorytm ten działa niederministycznie, dlatego potrafi osiągnąć szybsze czasy działania dla 
większych instancji. Jednak procentowe szanse rozwiązania danego problemu są najmniejsze.

\subsubsection{Algorytm Tabu search}

Algorytm TS działa w mniejszych instancjach wolniej od algorytmów Steepest i Greedy, ale
ok. 4 razy szybciej niż algorytm SA. W większych instancjach (ok. 100 elementów) czasy 
działania algorytmów TS i SA się zrównują. Przy wielkości 200 elementów TS jest już 
dwukrotnie wolniejszy od symulowanego wyżarzania. We wszystkich przypadkach Tabu search 
jest wolniejszy od algorytmów Greedy i Steepest.

\subsubsection{Algorytm symulowane wyżarzanie}

Algorytm SA uzyskuje najlepsze wyniki czasowe, licząc największe instancje (ponad 700 
elementów) poniżej 7 min. Algorytm Greedy, który jest drugi w zestawieniu potrzebował 
około 1 h. Biorąc pod uwagę jednak małe instancje (ok. 50 elementów) do ich obliczenia 
potrzebował ponad 30 sekund, podczas gdy algorytm Greedy potrafił je rozwiązać w 0,04 
sekundy.

\subsection{Ilość iteracji}

Porównując ilość iteracji algorytmów Greedy i Steepest można zauważyć, że algorytm 
Steepest wykonuje ok. 4 razy mniej kroków od algorytmu Greedy. Jest to spowodowane 
dokładnym przeglądaniem przestrzeni sąsiedztwa i wybierania najlepszego rozwiązania.

Nawiązując jednak do ilości przejrzanych rozwiązań można zauważyć, że algorytm
Greedy przegląda ich ok. 50\% mniej, co istotnie wpływa na szybkość obliczeń.
